# 摘要

自动关键字提取算法旨在识别文档中包含核心信息的单词和短语。

为克服现有无监督关键短语提取方法的局限性，提出了关键短语语义多样性和关键短语覆盖率两个特征。

关键短语语义多样性是指提取结果中语义变化的程度，引入关键短语语义多样性是为了避免提取包含相同高分候选词的同义词短语。

关键词覆盖率是指候选词在文档中对其他词汇的代表性。

本文提出了一种称为TripleRank的无监督关键短语提取方法，它评估三个特征:单词位置(学术文档的一个敏感特征)和上面提到的两个创新特征。TripleRank的体系结构包括对三个特征进行评分的三个子模型和一个求和模型。

TripleRank虽然涉及多个模型，但并没有典型的迭代过程；因此，计算成本相对较低。TripleRank在四个学术数据集上的实验结果与四个最先进的基线模型进行了比较，证实了关键短语语义多样性和关键短语覆盖率的影响，证明了本方法的有效性。

# 一、介绍

针对对象：学术论文。

对于监督方法，问题被视为一个`分类任务`。早期算法的一个例子是关键短语提取算法(KEA)。在这种方法中，训练模型来区分一个单词是否是关键短语。如果一个单词在目标文档中出现的频率较高，而在一般情况下出现的频率相对较低，则它更有可能被归类为关键短语。有监督算法比无监督算法更准确，但需要人工标记来准备大型语料库。

对于无监督方法，任务被视为`排序问题`。精确度不如有监督方法，但计算成本低。无监督方法包括基于图的排序、基于主题的和同步学习。

使用不同的工具，包括位置信息、图表和主题模型，许多关键短语提取算法都获得了出色的结果。然而，我们发现了以下在大多数模型中经常出现的问题。许多模型根据概率和权重确定的分数来评估学术文献中的术语和短语，这在大多数情况下是准确的。对包含多个单词的短语的提取通常由它们所包含单词的权重和概率评分所主导，这是潜在的不准确性所在。一个得分或权重较高的单词更有可能是几个短语的一部分。因此，该模型可以预测多个包含与关键短语结果相同的高分词的短语，而忽略它们相似的语义(意思就是，原本让输出三个关键短语作为关键词，结果输出了三个意思一样的)。

为了解决这一问题，我们开发了两个创新功能——关键短语覆盖和关键短语语义多样性，并提出了一个名为TripleRank的模型。我们对来自图1的文档的方法的结果在“支持证据”部分给出。

![1670054503570](D:%5CTypora%5Cuser-image%5C1670054503570.png)

**关键词覆盖率**是指一个词的覆盖范围或其代表性超过其他词。关键短语是应该代表整个文档并总结其内容的术语和短语。因此，也可以认为关键短语在这些文档中总结或覆盖了更多的语义内容。**关键词语义多样性**是指提取的关键词语义分布的广度。集中到较少域的提取结果具有较低的关键词语义多样性。我们最大限度地利用关键字语义多样性和关键字覆盖率来避免上述问题。

在本文中，我们提出了TripleRank，它利用了三个特征:`关键词覆盖`、`关键词语义多样性`和`位置信息`。我们通过评分来评估三个特征，并将它们与最终评分的输出统一起来。构建三个子模型：

1. 关键字覆盖子模型是基于相似度计算和处理的。
2. 关键词语义多样性子模型用来预测每个候选词的潜在主题分布。
3. 位置信息子模型被建立是因为学术文献的特定属性，也就是学术文献具有辨识度较高的写法。

本文主要贡献：

- 解决了一个常见的问题，即几个提取的短语包含相同的高分单词。
- 提出并分析了关键词覆盖和关键词语义多样性这两个概念的产生原因和意义。
- 提出了TripleRank方法，这是一种基于关键短语覆盖率、关键短语语义多样性和位置信息的方法，与现有的模型相比具有更好的精度。
- 提出了一个计算效率高的模型，该模型是部分预训练的，在主体中没有典型的迭代过程。

# 二、相关工作

TextRank、SingleRank和PositionRank是基于图的关键短语提取的最新方法。

主题PageRank (TPR)是一种很重要的方法，Liu将文档的语义主题作为衡量候选词得分的标准。与基于候选人相关词汇数的排名方案(如TextRank)相比，TPR是一个两阶段的过程，其中有一个构建主题解释器的特色过程。

LDA是一个广泛使用的主题模型，它可以生成单词和文档的主题分布。

TopicRank模型首先根据话题关系建立了一个候选词图表，并将属于同一话题的候选词视为同等重要。在后排序启发式中，每个主题中最具代表性的候选词被选出。

PositionRank是一个无监督的、基于图的模型，它将位置信息合并到一个有偏置项的PageRank算法中。候选词的出现位置被计算为有偏PageRank算法中的权重。

embedding算法——包括Word2Vec、Doc2Vec、GloVe和BERT——也有助于关键短语提取作为语义表示的常用方法。

# 三、提出的模型

TripleRank的体系结构由三个子模型组成，评分特征包括关键短语覆盖率、关键短语语义多样性和位置信息。

如图2所示，对三个特征分别打分，然后通过数学方法(包括加权和和加权调和和)组合得到综合排名得分。

![1670056491775](D:%5CTypora%5Cuser-image%5C1670056491775.png)

`关键短语覆盖率评分评估提取的关键短语可以表达的文档中内容的广度`。候选词和文档中其他词之间的相似度对于关键短语覆盖率的评分是有效的，因为相似度越高表示代表性越好。为了获得这种相似性，我们将单词嵌入到单词向量中，它拥有通常相关的相邻单词的语义信息。因此，我们使用词向量来评估候选词与其他词的接近度，从而评估其覆盖水平。

`关键短语语义多样性评分通过涉及更多的主题来提高关键短语的准确性，以避免短语涉及排名列表中相同的高权重词的情况`。使用主题模型LDA来评估关键短语的语义多样性。LDA模型是一个研究完善、适用性广的模型，是提高模型性能的最佳方法。关键词语义得分是根据候选词所属主题的概率计算的。利用LDA输出的主题分布，可以提高抽取结果中的主题影响，避免语义相似的短语。

`职位信息得分是由职位顺序获得的`，这是受PositionRank启发；但是，作者没有使用PageRank的过程，只保留了位置权重。

`最后的分数是结合三个特征的归一化分数计算出来的`。

## 1、关键词覆盖率

在实验的模型中，关键词覆盖率使用Word2Vec进行评估。Word2Vec是一个词嵌入算法，它在向量空间中提供词的分布式表示。通常，Word2Vec有两种方法：连续的单词袋(CBOW)和skip-gram。

CBOW模型的训练输入是特定单词的上下文单词的词向量，输出是该特定单词的词向量；skip-gram输入是特定单词的单词向量，输出是特定单词的上下文单词向量。

CBOW在小型语料库中更有效，而skip-gram在大型语料库中表现更好。因此，我们的实验选择了skip-gram。

我们的目标是**预测训练过程中的上下文单词**，假设训练语料库中有特定的词汇。输入词称为目标词，上下文词是目标词周围的词，其预测概率是输出。

在skip-gram模型体系结构中，输入层是目标词的独热编码词向量。独热编码表示一个V(根据词汇表大小)维向量{$x_1,\dots,x_V$}，其中只有元素$x_k$为1，其它元素均为0。隐藏层大小为N，表现为一个N维向量{$h_1,\dots,h_n$}。输出层是一个$C\times V$的矩阵，表示为{$y_{11},\dots,y_{CV}$}，其中C表示上下文中的字数。相邻层单元是全连接的，输入层与隐藏层之间的权重用矩阵$W_{V\times N}$表示，隐藏层与输出层之间的权值用矩阵$W'_{N\times V}$表示。

当训练一系列的单词$w_1,w_2,\dots,w_t$时，skip-gram模型的目的是最大化平均对数概率：
$$
\tag{1}
\frac{1}{T}\displaystyle\sum^T_{t=1-c≤j≤c,j\not =0}\sum \log p(w_{t+j}|w_t)
$$
通过输出层的softmax函数来输出单词的后验分布：
$$
\tag{2}
p(w_O|w_I)=\frac{exp(v'_{w_O}Tv_{w_I})}{\displaystyle\sum^W_{w=1}exp(v'_wTv_{w_I})}
$$
通过共享相同权重矩阵面板计算输出层上有C个后验分布，代表对C个上下文词的预测。为了使(1)最大化，表达式(2)的的表示也应该最大化。然而，softmax的skip-gram式子对于较大的增量$\log p(w_O|w_I)$可能需要过多的计算资源，因此采用分层softmax方法。

关键词覆盖率是通过词向量之间的相似度来评估的，我们使用余弦相似度。角度越小，表示单词之间的相似度越高。关键词覆盖率得分是由所有候选词对的相似性之和计算的：

![1670140895922](D:%5CTypora%5Cuser-image%5C1670140895922.png)

其中，$Coverage$是覆盖率得分，$Similarity$是两个词向量的余弦相似度，$\vec{w_{j\neg i}}$是文档中除了词$w_i$的词的词向量。

## 2、位置信息

位置信息是我们算法使用的另一个重要特征，它由PositionRank模型的一部分进行评估。PositionRank利用学术文献的细节，重要的词出现在文章的前面。该算法分为三个阶段：

1. 字级图构造；
2. 具有位置偏置的PageRank；
3. 候选短语的构成。

整个模型是一个根据位置信息计算权重的有偏PageRank。同样，在模型中，计算候选词的出现顺序作为得分，而PositionRank将其作为偏见。但是，作为三个特点之一，为了保持整个模型的简洁和经济，没有使用任何迭代过程和图的构造。因此，职位信息得分的计算方法如下。为了检验简化是否有效，PositionRank将其作为基线模型之一进行了实验。P是一个单词在d中出现次数的总和：

位置信息得分的计算方法为：设d是一个用于关键短语提取的文档，其中包含单词$w_i$。权重因子$p_{w_i}$被计算为所有发生的位置顺序的倒数之和：

![1670141701731](D:%5CTypora%5Cuser-image%5C1670141701731.png)

其中，positon $\alpha$是$w_i$的第$\alpha$个出现顺序。

考虑下面的具体示例。如果一个单词出现在目标文档的第4、6和8个位置，则计算权重为：

![1670141917147](D:%5CTypora%5Cuser-image%5C1670141917147.png)

据此，我们便得到了模型的位置信息得分。因此，我们提出：

![1670141961756](D:%5CTypora%5Cuser-image%5C1670141961756.png)

其中，$ \operatorname*{Position}(w_i) $是候选词$w_i$的位置信息得分。

## 3、关键词语义多样性

关键词语义多样性的评估采用LDA，一种离散数据集合的生成概率模型，具有三级贝叶斯模型。LDA模型可以生成文档和单词的主题分布。在我们的模型中，LDA模型描述了关键短语语义多样性的三个重要特征之一。我们的目标是最大化主题多样性，并从提取结果中剔除语义相似的短语的不同形式。因此，对单词和短语的主题概率进行评分，并在最终评分中排名。

LDA模型通过带有板块、主题板块、文档板块和单词板块的抽样过程生成单词。假设语料库W包含V个单词，M个包含$N_m$个单词的文档，K个主题。上述过程可以用Dirichlet-multinomial一元模型来描述，该模型基于以下理论：
$$
\tag{7}
Posterior=\frac{likelihood\cdot prior}{evidence}
$$
图3展示了LDA的网络，其中$\vec{\alpha}$和$\vec{\beta}$为超参数，$\vec{\theta_m}$为文档m的主题混合比例，$\vec{\ \varphi _k}$为主题k的混合分量，$z_{mn}$为文档m中第n个单词选择主题的混合指标，$w_{mn}$为文档m中第n个单词的术语指标。

![1670146846965](D:%5CTypora%5Cuser-image%5C1670146846965.png)

网络是一个由两个Dirichlet-multinomial一元模型构造的生成过程：

![1670145229988](D:%5CTypora%5Cuser-image%5C1670145229988.png)

其中，符号“$\rarr$”是一个抽样过程。联合分布可以被因式分解。Gibbs是MCMC模拟的一种特殊情况，在LDA中用作近似推理的方法。采用Gibbs抽样后，结果如下：

![1670145368794](D:%5CTypora%5Cuser-image%5C1670145368794.png)

其中，$i=(m,n)$对应文档m中的第n个单词，t为$w_{mn}$的术语，$n^{(k)}_m$和$n^{(t)}_k$为计数统计。

训练过程相对较短。我们为语料库中的每个单词w随机分配主题指示符z。随后，我们使用(10)对主题进行抽样，直到吉布斯抽样收敛。

主题词共现矩阵是LDA模型的结果。

训练过程相对较短。我们为语料库中的每个单词w随机分配主题指示符z。随后，我们使用(10)对主题进行抽样，直到Gibbs抽样收敛。主题词共现矩阵是LDA模型的结果。输出是一个单词字典和一个主题概率分布。一个词的最高概率主题被认为是这个词的主题。

关键词语义多样性得分是候选词所属主题的概率：
$$
\tag{11}
Diversity(w_i)=p(z_i|w_i)
$$
其中，$w_i$和$z_i$分别代表候选词和$w_i$所属的主题。

## 4、评分方案

我们的关键词提取算法是一种无监督算法，它利用了单词的隐式特征。与以往的研究相比，我们的算法忽略了传统的迭代(LDA模型在训练过程中使用迭代，而我们的算法几乎没有使用通用的训练结果)。特征和评分的组合(图4)基于超参数和加权平均。在组合之前，需要对位置评分和关键词覆盖率评分进行归一化。

![1670248442716](D:%5CTypora%5Cuser-image%5C1670248442716.png)

![1670248522525](D:%5CTypora%5Cuser-image%5C1670248522525.png)

其中，$w_i$是一个候选词，$C_i$是归一化的关键短语覆盖率得分，v是候选词的数量，$P_i$是归一化的位置得分。关键词语义多样性得分以概率为单位；不需要标准化过程。

组合过程主要分为两个部分：

1. 关键词语义多样性得分和关键词覆盖率得分的加权和。
2. 位置得分和1中加权和的加权调和平均数。

1中，关键词语义多样性得分和关键词覆盖率得分被汇总到$D_i$。关键词语义多样性和关键词覆盖率被看作用来帮助优化准确性的函数。当需要对具有不同重要性的单元进行求和时，往往会使用加权求和。通过重复的尝试，根据最好的结果，我们决定给关键词覆盖率和关键词语义多样性分配权重分别为0.3和0.7。随后，在主题重要性的基础上对求和结果加入一个优化因子，旨在提高主题特征的影响，并将其归一化：

![1670291281304](D:%5CTypora%5Cuser-image%5C1670291281304.png)

其中，$N_{z_i}$是相同主题下单词的数量，v是候选词的数量，$D_i$是关键词覆盖率和关键词语义多样性求和后的归一化评分。

2中，我们已经组合了关键词覆盖率和关键词语义多样性，接下来的求和过程通过加权调和平均值实现。相较算术平均值，加权调和平均值易受上、下值的影响，其中较低的值的影响更大。因为我们只有两个变量，一旦$D_i$和$P_i$太低，合成就会退化。因此，通过加入加权调和平均值用于分值，我们应该得到一个更加集成的最终分数。根据$D_i$包含两个特征和我们的反复实验，$D_i$和$P_i$的超参数权重分别设为0.8和0.2。因此，我们得出了以下最终得分：
$$
\tag{15}
S_i=\frac{0.16\cdot D_i\cdot P_i}{0.8\cdot D_i+0.2\cdot P_i}
$$
其中，$S_i$，$D_i$和$P_i$分别代表候选词$w_i$的最终得分，关键短语覆盖率和关键短语语义多样性的归一化评分和归一化的位置评分。

根据候选短语在文档中的连续出现形成候选短语。只有以名词长度不超过3结尾(也就是一个短语最多由三个词构成)的短语才被认为是候选短语。短语得分计算为单个单词的最终得分之和。完整的算法如算法1所示：

![1670293188283](D:%5CTypora%5Cuser-image%5C1670293188283.png)

# 四、实验与结果

## 1、实验数据集

实验使用了四个数据集：知识发现和数据挖掘(KDD)、万维网会议(WWW)、Inspec和文档理解会议(DUC)。KDD和WWW是从CiteSeerX数字图书馆编译的，包括Gollapalli和Caragea在两次ACM会议上的研究论文。自1898年以来，Inspec一直是科学和技术文献中使用的一个数据集。数据集的统计结果如表2所示，并有一个实验发现。

![1670293561824](D:%5CTypora%5Cuser-image%5C1670293561824.png)

## 2、评价指标

实验中使用的评价指标包括精度(Pre)、召回率(Re)和F1得分(F1)。Precision, recall，和F1-score表示：

![1670293679019](D:%5CTypora%5Cuser-image%5C1670293679019.png)

其中，$c_{correct}$是正确提取关键短语的数量，$c_{extract}$是总的提取关键短语的数量，$c_{standard}$是作者或注释给出的关键词语的提取数量。为了提供客观的结果，在实验中加入了这三个评价指标。在三个标准中，我们将F1−Score作为实验的综合指标，并将评价结果与四种基线方法进行了比较。

## 3、总体表现(整体性能)

为了检验TripleRank的性能，我们选择了四种强基线无监督方法。我们主要将我们的算法与MultipartiteRank和PositionRank这两种最先进的竞争基线方法进行比较。此外，我们使用了类似的功能，位置信息，如在PositionRank和MultipartiteRank使用了类似的概念，关键字短语覆盖；因此，我们将TripleRank与它们进行比较。考虑到其他普通的方法，我们选择了TPR和Yake两种在我们的实验中相对较差的方法。实验方案和基线方法设置均基于PKE。

性能指标：精度、召回率、F1得分、k = 4、6、8和10个预测关键短语的MRR。k的值选择在4到10之间，原因是旨在减少同义词短语的出现。当预测的关键词太少时，增强可能是不切实际的。

TripleRank优于四种基线方法。作为竞争性基线方法，MultipartiteRank和PositionRank在某些指标上与结果持平或显示出优势；然而，它们都不是综合指标f1得分。在附录A所示结果的完整版本中，当k的值从1到3时，我们的结果显示的优势较小。这符合我们的预测，即TripleRank提高性能的方式是基于更多的预测尝试。此外，这一现象也间接说明了TripleRank比以往模型的提升是建立在一个`高分词解决同义词短语问题`的基础上的。

![1670312609711](D:%5CTypora%5Cuser-image%5C1670312609711.png)

![1670312643001](D:%5CTypora%5Cuser-image%5C1670312643001.png)

![1670312658456](D:%5CTypora%5Cuser-image%5C1670312658456.png)

图5显示了四个数据集的F1-Score图，上面的图是四个模型在k基础上的表现，下面的图是TripleRank和表现最好的基线模型之间的差距。从图5(a)(b)可以看出，TripleRank的优势在DUC和Inspec中更加明显。另一方面，在KDD和WWW数据集中，结果更接近，但TripleRank通常也领先。但是，当预测8到10个关键字时，曲线趋势接近于PositionRank的曲线。换句话说，当k在4到8之间变化时，我们的方法性能更好。这一现象可以解释为，随着k的增加，同义词的影响逐渐减小，因为容错能力增加了。

总的来说，虽然优势随着k的取值而浮动，但我们在实验中证明了TripleRank的性能全面优于其他基线模型。

![1670312763878](D:%5CTypora%5Cuser-image%5C1670312763878.png)

## 4、支持依据

图1为DUC文档中PositionRank的提取结果。为了便于比较，我们将方法的提取结果添加在图6中。

![1670312954865](D:%5CTypora%5Cuser-image%5C1670312954865.png)

结果显示，TripleRank在6次尝试中预测了5个正确的关键短语，而PositionRank预测了4个。然而，单一文档的结果是有限的。我们主要使用这个示例来说明我们的方法与其他方法的区别和增强。在我们的结果中，“PLO”和“state”出现的权重是高单词的两倍，而大多数出现都是正确的。相比之下，PositionRank的对照在四个短语中包含了“PLO”。TripleRank提取的关键短语在语义上更加分散，这得益于关键短语语义多样性和关键短语覆盖率的合理使用。

## 5、数据集的影响

可以看出，TripleRank的性能在不同的数据集中是波动的。

k = 10时，Inspec与DUC的f1评分差距达到10.3%。Inspec是我们的方法执行非常出色的实验数据集。我们担心这个巨大的差距可能是实验失误造成的。值得欣慰的是，其他四种基线方法在结果上也显示出类似的差距，这将我们的注意力转移到了数据集的影响上。

我们陈述了作者指定关键短语在原始文档中实际出现的次数，发现作者指定关键短语在文档中出现的可能性较低。具体统计情况如表2所示。

![1670313656585](D:%5CTypora%5Cuser-image%5C1670313656585.png)

作者指定关键短语的平均出现次数明显低于KDD和WWW。由于KDD和WWW的实际关键字出现情况相似，它们显示出了相似曲线，如图7所示。作者给出的关键字的出现对关键字提取算法影响很大，因为排序是基于文档中出现的单词，而评价主要是基于作者输入的关键字。一旦作者给出的关键短语没有出现在文档中，预测就更有可能是无效的。如图7(b)所示，将TripleRank的结果用文献中实际出现的平均值归一化后，曲线更加接近，分布更加合理。学术文献KDD和WWW数据集的结果上升到领先地位。尽管支持的证据是在DUC数据集中，TripleRank仍然表现更好的学术文献。

![1670314127331](D:%5CTypora%5Cuser-image%5C1670314127331.png)

# 五、结论

在本文中，我们开发了关键短语语义多样性和关键短语覆盖两个创新特性来解决现有方法中存在的同义词短语出现问题。结合这两个特征和位置信息，我们提出了TripleRank关键字短语提取方法。实验结果表明，TripleRank方法在精度上优于基线方法，主要是通过关键短语语义多样性和关键短语覆盖率来提高结果。此外，消除了传统关键字提取模型中存在的不必要的迭代，提高了计算的成本和效率。

在未来的研究中使用基于强化学习的序列对序列模型来提取文本中没有出现的关键短语。