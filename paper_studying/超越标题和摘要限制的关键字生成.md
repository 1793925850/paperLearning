# 摘要

在本文中，我们全面探讨了来自给定文章全文或语义相似文章的附加信息的集成是否对神经关键字生成模型有帮助。

我们发现，从全文中添加句子，特别是以文章的提取摘要形式添加句子，可以显著改善文本中存在或不存在的两种类型关键短语的生成。

还提出了一个新的大型学术数据集FULLTEXTKP用于关键词生成。与以前的大规模数据集不同，FULLTEXTKP包括文章的全文以及标题和摘要。

# 一、介绍

在本文中，没有从文档中提取关键短语，而是将问题建模为一种神经序列到序列(seq2seq)方法，我们学习以自回归的方式生成关键短语。这种方法不仅可以准确预测文档中出现的关键字(当前关键字)，还可以预测语义相关但文档中不存在的关键字(不存在关键字)。

我们建议扩展输入序列的信息源，目前仅局限于标题和摘要。

在本文中，我们提供了创新的方法来使用文档的某些部分，这些部分可能是丰富的信息源，例如，使用来自文档内容的引用句或文档的提取摘要(如表1所示)。

![1672281142534](D:%5CTypora%5Cuser-image%5C1672281142534.png)

通过综合实验，我们发现，引文上下文或出处曾是关键短语提取任务的丰富信息源并不是关键短语生成任务中最丰富的信息来源。相反，我们观察到，如果我们总结文档并使用文档的摘要而不是文档本身，那么来自文档的语义信息可以得到最好的吸收。

值得注意的是，基于合并摘要的方法在很大程度上优于仅使用标题和摘要的方法，通常在有关键字和没有关键字的情况下，性能都提高了2-3倍。

贡献：

1. 探索了将来自不同数据源的额外信息(不仅仅是标题和摘要)集成到神经seq2seq模型中用于关键短语生成(即预测存在和不存在的关键短语)的好处。不同的数据源包括来自文章正文的随机句子，来自正文摘要的句子，引用句，非引用句，以及来自训练集中其他相关文档的句子。
2. 实验表明，从文章正文中提取摘要的句子是为关键词生成找到好内容的重要来源。
3. 提供了一个新的数据集FULLTEXTKP，包含约14万篇文章，每个文章都有全文。

# 二、相关工作

**关键词生成。**最近的关键短语生成方法主要是神经seq2seq模型，因为它们也提供了一种机制来生成缺失的关键短语。

**外部信息。**

**数据集。**

# 三、方法

使用了四个不同的模型，其中三个是关键短语生成任务中常用的模型，即catSeq, One2Set, ExHiRD；第四种模型是基于最新的Transformer模型之一，即Longformer Encoder-Decoder(LED)，适用于长文档。每个模型中的基线将标题和摘要(T+A)作为输入，并预测关键短语序列。

通过将不同类型的数据连接到标题和摘要(T+A)来探索每个模型的不同扩展(表1中也有说明)。在附加信息的连接过程中，我们在标题和摘要之间以及所有附加句子之间使用分隔符，如下所示：

![1672964874703](D:%5CTypora%5Cuser-image%5C1672964874703.png)

我们描述下面不同类型的数据(输入序列)：

$T+A+RANDOM$：对于这种设置，我们将k个随机选择的句子(从正文中)按照它们在正文中出现的原始顺序连接到标题和摘要。

$T+A+CITATION$：在这个设置中，我们收集所有(从正文中)引用过其他文章的句子。我们把这样的句子称为`引证句`。我们从整个库中随机选择k个句子，并按照它们在给定文章正文中出现的顺序将它们连接到标题和摘要。引用句的合并受到Naïve-Bayes或基于textrank的方法或CitationGraph的构造的启发，这些方法通过集成引用信息来增强关键词提取性能。

$T+A+NON-CITATION$：在这个设置中，我们收集了所有(从正文中)没有引用任何其他文章的句子。我们从整个库中随机选择k个句子，并按照它们在给定文章正文中出现的顺序将它们连接到标题和摘要。

$T+A+SUMMARY$：在这种方法中，我们使用最先进的无监督摘要算法PacSum来总结文章的主体，并从摘要中添加k个句子到文章的T+A。Zheng和Lapata表明，基于tf - idf的PacSum优于TextRank和其他基线，甚至与基于bert的PacSum也具有很强的竞争力。PacSum可以被其他的摘要算法所取代，但是我们选择基于tf - idf的PacSum作为一种强大而高效的无监督摘要模型的代表来测试摘要正文的有效性。

使用PacSum获取文档的提取摘要的步骤如下：

1. 把一个文档看作一个句子列表，每个句子看作一个单词列表。整个文档可以可视化为一个有向图，其中单个句子是节点，边缘根据相似度加权。
2. 首先计算tf-idf来理解句子集合(文档)中一个单词与一个句子的相关性。
3. 然后计算每对句子之间的相似度。
4. 接下来，计算一个阈值，在此基础上，将相似性分数归一化。
5. 随后，计算有向边的前向和后向边缘分数。
6. 然后，计算文档(图)中句子(节点)的度中心性，作为向前和向后边缘得分的加权平均值。
7. 最后，根据中心值对句子进行排序，选择k个排名最高的句子，并将它们连接到标题和摘要。

$T+A+RETRIEVAL-AUGMENTION$：在该方法中，我们从训练语料库中检索并增加k个语义相似的句子到每篇文章的T+A。为此，首先从整个训练数据集中的文章标题和摘要中创建一组所有句子。接下来，使用SPECTER将每个句子嵌入到集合中。我们将这些嵌入视为表示相应语句(值)的键嵌入。给定一个目标文章(查询)，然后使用SPECTER嵌入它的标题和摘要。这种嵌入作为查询嵌入，从其他文章中搜索相关句子。随后，我们使用FAISS计算查询嵌入与所有关键嵌入的点积相似度。最后，我们选择k个句子(值)对应于前k个最相似的关键嵌入，并将这些句子连接到查询文章的标题和摘要。

# 四、实验设置

## 1、FULLTEXT数据集

为了评估利用不同类型信息的模型的性能，我们构造了一个新的数据集，称为FULLTEXTKP。

![1672969024431](D:%5CTypora%5Cuser-image%5C1672969024431.png)

## 2、评估

将最大序列长度限制为800。

# 五、结果

在本节中，我们首先给出§5.1中§3中描述的不同方法的存在和不存在关键短语生成性能的结果。我们进一步探索了我们的最佳性能方法，即T+A+summary分为两个子类：提取和抽象摘要方法(§5.2)。最后，在§5.3中，我们探索了最佳性能模型的性能，即序列长度远高于800的Longformer Encoder-Decoder。我们将所有实验进行三次，并报告平均值。

## 1、存在和不存在的关键词生成

表3和表4分别给出了不同实验中存在关键短语和不存在关键短语表现的结果。

![1673572669162](D:%5CTypora%5Cuser-image%5C1673572669162.png)

![1673572751805](D:%5CTypora%5Cuser-image%5C1673572751805.png)

结果表明，`从给定文章的正文中添加额外的信息到基线(T+A)对当前和不存在的关键字生成都是有益的。`与任何其他方法相比，增加总结句对出现和不出现关键短语的表现都提供了最实质性的提升。直觉，`文章的摘要包含了对生成关键字最有用的时事信息。`

图1进一步验证了上述直觉。摘要法是现代关键词最丰富的来源。

![1673573164523](D:%5CTypora%5Cuser-image%5C1673573164523.png)

可以看出，当使用Summary方法的这种高度主题化的输入文本进行训练时，模型可以更好地学习泛化。

## 2、摘要方法分析

在表5中，我们比较了T+A+Abs_Sum与T+A+Summary (extractive)方法的结果。

![1673574660321](D:%5CTypora%5Cuser-image%5C1673574660321.png)

结论，增加重复语句或带有冗余信息的语句作为摘要，对关键词生成性能没有帮助。

## 3、用Longformer Encoder-Decoder探索更长的序列长度

LED能够处理高达16000个令牌的序列长度。

表6中的结果显示，随着源文本长度的增加，存在和不存在关键短语的性能通常都会增加。

![1673574922482](D:%5CTypora%5Cuser-image%5C1673574922482.png)

在表7中，展示了使用LED模型的最佳性能方法T+A+ (Extractive) Summary的样本预测。

![1673575400661](D:%5CTypora%5Cuser-image%5C1673575400661.png)

从表格中得出以下结论。首先，该模型能够准确预测关键字的出现和缺失。其次，一些预测的关键字与黄金关键字接近匹配，尽管它们具有关键字的质量，但由于度量(精确匹配)的限制，它们对模型性能没有贡献。

# 六、结论

在本文中，我们探索了许多方法，以结合来自`学术文档`主体的额外数据，以`提高关键字生成`任务的性能。我们从结果中得出结论，提取摘要句是论文的核心，为提高当前和不存在的关键短语生成性能提供了最热门的信息。引文、非引文和随机句也带来了补充信息，在一定程度上提高了性能。其他一些方法，如从其他论文中增加语义相似的句子或增加抽象的摘要句，给标题和摘要带来重复或冗余的信息，是无效的。我们对包括LED在内的四种尚未探索的模型进行了全面分析。我们的工作旨在打破只使用标题和摘要的障碍，并提供了一个大型数据集，其中包含关键词生成的全文。

# 七、局限

所提出的方法的局限性之一是，与仅使用文章中的T+A的模型的常规训练相比，模型训练的计算时间和内存增加了(高达2-3倍)。此外，我们的最佳执行方法T+A+Summary需要为所有文章的预计算摘要提供额外适度开销。

另一个潜在限制是，我们不能直接将我们的模型与广泛使用的数据集进行比较，例如KP20k, Inspec, Krapivin, NUS，因为这些数据集没有论文全文。为了全面起见，我们考虑了四种模型在新数据集上的性能。