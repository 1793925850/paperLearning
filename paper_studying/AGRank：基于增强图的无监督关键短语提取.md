# 摘要

本文将图和深度学习方法相结合，提出了一种基于增强图的无监督(UKE)文档关键短语识别模型。该模型利用预训练BERT模型中提取的相互注意来构建候选图，并在图中增加全局和局部上下文节点来提高性能。提出的模型在四个公开可用的数据集上对13条UKE基线进行了评估。结果表明，该模型对长、短文档都是一种有效的鲁棒UKE模型。

# 一、介绍

主流UKE方法分为三种类型：统计学方法、基于图的方法、深度学习方法。

统计学方法包括基于TF-IDF的方法和其它近期工作，它利用词频，文档频率，单词偏移量和n-grams数目来计算候选词的重要性。

基于图的方法将候选词视为图中的节点。边的计算基于候选词的共现、语义相似度，或者其他关系。然后，基于图的算法确定候选词的重要性。最近的一些研究表明，基于嵌入(embedding)的方法可以在无监督关键字提取方面取得优异的性能，例如JointModeling、AttentionRank、SIFRank、KeyGame和EmbedRank。这些方法将候选词的重要性建立在候选词的embedding的距离或相似性上，有些考虑了全局或局部上下文。

本文提出了一种基于增强图的无监督模型来识别文档中的关键字。该模型从预训练的BERT模型中提取注意力，来生成候选关键字图，然后在注意力图中添加表示全局和局部上下文的节点。与基线方法类似，名词短语被提取为代表图中节点的候选词。候选词的共现决定了句子上下文中的图中的边。基于从预训练BERT模型中提取的相互注意和候选词所在句子的索引，计算候选词之间的边的权值。候选图添加全局和局部上下文作为文档和句子节点。基于文档节点与候选词节点之间的余弦相似度计算文档节点与候选词节点之间的边权值以及句子节点与候选词节点之间的边权值。然后，根据文档频率和边权值，通过删除节点和边来调整图。最后，使用加权PageRank算法计算每个候选词的排名。

> 本文贡献总结如下：

- 提出了一种考虑全局和局部上下文的基于增强图的无监督关键词提取(UKE)模型，并使用四个基准(参照)数据集对其进行了评估。
- 利用从预训练语言模型中提取的相互注意构建加权图。
- 所提出的模型比最先进的UKE基线工作得更好或具有竞争力。

# 二、方法论

> 模型有三个主要部分：

1. 候选图生成，将每个文档转换成一个加权图，候选词作为节点，句子上下文中候选词之间的注意作为加权边；
2. 图增强，通过添加文档节点和句子节点，以强调全局和局部上下文及其与候选词的关系；
3. PageRank评分，在图上应用加权PageRank算法对候选词进行评级，以识别关键词。

## 1、候选图生成

首先从文档中提取候选词，然后基于句子级自注意力机制在每对候选词之间添加加权边。此外，边权值还受到包含候选词对的句子的重要性的影响。

**候选词生成。**候选词提取使用先前方法中实现的模块。模块首先使用词性(PoS)标记名词、动词、代词和形容词。然后，使用NLTK包提取名词短语作为候选词。在我们的研究中，除了“-”之外，候选词中的标点符号都被删除了。该词干应用于候选词和基本事实关键字，用于模型构建和性能评估。在“去除”研究部分，研究了阻塞的有效性(该实验最后要去除一部分节点，所以要研究去除到什么程度停止去除工作)。

**边权重生成。**边权值的生成基于从预训练BERT模型中提取的候选词之间的相互注意力，结果表明，在预训练BERT模型的注意力图中成功捕获了重要的句法和语义信息。词与词之间的注意力聚集成短语之间的注意力。

对于一个有n个单词的句子，单词之间的相互注意力映射可以表示为矩阵(A)。

![1670494547225](D:%5CTypora%5Cuser-image%5C1670494547225.png)

$a_{ij}$同一句话s中，单词$w_i$对单词$w_j$映射的注意力值。如果候选词是一个包含多个单词的短语，那么其注意力值为所构成的单词注意力值的总和。给定候选短语$c_1=\{w:w_i\in c_1\}$，有n个单词；候选短语$c_2=\{w:w_j\in c_2\}$，有m个单词。$c_1$和$c_2$之间的注意力是$c_1$中的单词投射到$c_2$中的单词的注意力之和，如式1所示：
$$
\tag{1}
a(c_1,c_2)=\displaystyle\sum_i^n\displaystyle\sum_j^ma_{ij}
$$
图1展示了短语之间相互注意力的可视化示例。给定一个文档的标题——“Standards for service discovery and delivery”，热图中的彩色行表示从y轴上标记的单词/短语到x轴上标记的单词/短语的关注项目。

![1670730296446](D:%5CTypora%5Cuser-image%5C1670730296446.png)

$a(c_1,c_2)$表示句子s中从$c_1$到$c_2$的有向边的权值，如式2所示：
$$
\tag{2}
v_s<c_1,c_2>=a(c_1,c_2)
$$
为了生成无向加权边，将所有包含$c_1$和$c_2$的句子从$c_1$到$c_2$以及从$c_2$到$c_1$的边的权值相加，如式3所示：

![1670730976890](D:%5CTypora%5Cuser-image%5C1670730976890.png)

**边权重调整。**一篇文章的前几句话往往总结了主要主题，并强调了工作的领域。因此，根据包含边的句子($i_s$)的位置来调整边权值($v$)。如式3所示：

![1670732665308](D:%5CTypora%5Cuser-image%5C1670732665308.png)

边($c_1,c_2$)的权值根据包含候选词$c_1$和$c_2$的第一个句子的索引($i_s$)成比例地增加。K是句子位置的阈值，当句子索引超过k时，句子中包含的边没有权值调整。K可以根据文档的长度以及句子的数量进行微调。`对于一篇长文章，阈值k可以设置为摘要或引言中的句子数。`不同领域的文章会有不同的k。

在接下来的切除研究中，我们探索了不同k的影响，k被设计为10的倍数。对于小于10句的短文档，k取值为10。

## 2、图增强

候选图不考虑每个候选词与文档的全局上下文之间的关系，也不考虑候选词与每个句子的局部上下文之间的关系。因此，我们添加文档和句子节点，用全局和局部上下文来增强候选图。

**文档节点。**候选词({$c_1,\dots,c_r$})被连接起来作为文档节点表示。文档节点d和候选词节点c之间的边权值为它们嵌入的余弦相似度，如式5所示：

![1670736551152](D:%5CTypora%5Cuser-image%5C1670736551152.png)

文档节点embedding($e_d$)和候选词节点embedding($e_c$)是通过将文档或候选词的文本表示形式输入预训练的BERT模型来生成的。BERT的自注意机制为文档的每个成员词生成基于上下文的embedding。文档或候选词节点的embedding是通过将节点的成员词embedding值相加来生成的。使用bert-embedding包来生成词级embedding。

$\alpha_d$是一个系数，用于调整文档和候选词之间的边权值。它可以设置为语料库中的平均句子数。

**句子节点。**句子节点使用其原始句子内容表示。句子节点embedding($e_s$)使用与文档节点embedding生成相同的方式生成。候选词c和句子s之间的边权值等于它们embedding的余弦相似度，如式6所示：

![1670763667317](D:%5CTypora%5Cuser-image%5C1670763667317.png)

图2显示了从数据集Inspec随机选择的文档的增强图的可视化示例。蓝色的节点表示有茎的候选节点。文档节点和句子节点分别是粉红色和绿色的。给出了候选词之间以及候选词节点到文档节点或句子节点之间的边权值。出于演示目的，边权值乘以10并四舍五入。原始文档内容如图3所示，并突出显示真实(被框选的)关键字。在本例中，'“Service Location Protocol ”是一个带标签的关键字。在增强图中，节点“Service Location Protocol”和“race”之间的边权值很高，这是利用BERT相互注意计算出来的。

“Service discovery”是另一个被标记的关键词，出现在四个不同的句子中。在增强图中，节点“Service discovery”与许多候选词节点有连接。这个例子表明，我们的增强图具有基于文档内容强调边和节点重要性的机制。

![1670764175225](D:%5CTypora%5Cuser-image%5C1670764175225.png)

![1670764184433](D:%5CTypora%5Cuser-image%5C1670764184433.png)

**图修剪。**为了降低计算成本和提高性能，我们根据NLP特征删除一些节点，并根据边权重分布删除一些边。如下步骤：

1. 当候选词节点的文档频率超过某个阈值时，删除该节点。高文档频率通常表明该术语在语料库中是通用的。对于每个语料库，计算所有候选语料库的文档频率，并通过EIbow定律确定阈值。
2. 当边权重低于阈值时，例如某条边的权重低于0.25，删除这条边。
3. 当边权重低于由句子候选边权重分布确定的阈值($p_s$)时，删除句子和候选词之间的边。

## 3、PageRank评分

剪枝图被输入加权PageRank算法，以计算每个候选词的重要性得分。候选词c的分数PR(c)计算如式7：

![1670832717511](D:%5CTypora%5Cuser-image%5C1670832717511.png)

其中，$ \delta $是阻尼因子，$c_n$是$c$的邻居节点，$B_c$是所有c的候选邻居的集合。$v(c,c_n)$是边$(c,c_n)$的权重。加权PageRank算法考虑了边内和边外的权重。由于我们有一个无向图，边内权值和边外权值是`相同的`。

在最终的排序中，文档节点和句子节点被排除，文档频率较高的候选对象，例如高于阈值$df_{\theta}$的候选对象也被排除。

# 三、实验

## 1、数据集

我们的模型的性能在四个基准数据集上进行了评估。数据集Inspec和SemEval2017包含短文档，数据集SemEval2010和Nguyen2007包含长文档。表1总结了数据集的基本统计信息。关键短语提取的性能使用排名前5、10和15的关键短语的F1分数进行评估。

![1670834013696](D:%5CTypora%5Cuser-image%5C1670834013696.png)

为了与基线进行适当的比较，我们遵循常用的做法，使用数据集Inspec的未受控注释关键字，并在实验中使用包含100个文档的SemEval2010测试集。所有提取和标记的关键字都是为了评估。

## 2、UKE基线

将模型与13个基线无监督关键字提取模型进行了比较，这些模型分为三类：

1. 基于统计学的模型：TF-IDF、YAKE！；
2. 基于图的模型：TextRank、SingleRank、TopicRank、PositionRank、MultipartiteRank；
3. 基于深度学习或混合模型：EmbedRank、SIFRank、KeyGames、JointModeling、AttentionRank、MDERank。

## 3、超参数设置

BERT-Base用于注意力提取和节点embedding生成。对每个数据集的超参数进行微调并按如下方式设置：

对于所有数据集，δ设为0.85，$α_d$设为语料库的平均句子数。对于Inspec和SemEval2017，k设置为10，$df_{\theta}$设置为5，$p_s$设置为60和75百分位。对于SemEval2010，k设置为20，$df_{\theta}$设置为25。对于Nguyen2007，k设置为90，$df_{\theta}$设置为45。由于计算成本和实际需要，SemEval2010和Nguyen2007的增强图中没有添加句子节点。

## 4、结果

表2使用F1@5、10和15比较了AGRank和基线UKE模型。基线模型的值是原始论文中给出的值或最近在其他论文中发表的更好的结果。由于并非所有数据集都在原始论文中使用，我们使用已发布的代码将基线应用于数据集。产生的结果被标记为*。

![1670843427186](D:%5CTypora%5Cuser-image%5C1670843427186.png)

# 四、消融实验

## 1、阻塞分析

候选词词干导致节点合并并改变图的结构。表3比较了添加词干和不添加词干时AGRank的性能。结果表明，在SemEval2017、SemEval2010和Nguyen2007上，词干改善了模型的性能。然而，Inspec上的改进并不显著。

![1670853060066](D:%5CTypora%5Cuser-image%5C1670853060066.png)

## 2、图增强与边权重调整分析

提出的模型通过添加文档和句子节点来增强图，以提供全局和局部上下文。我们在表3中展示了上下文节点的影响。该模型更好地利用了Inspec上的文档节点添加功能。相比之下，句子节点的添加对SemEval2017模型性能的贡献更大。

有趣的是，在不添加文档节点的情况下，SemEval2010和Nguyen2007上的模型性能略好。我们认为`为长文档生成的文档节点不能通过生成单个embedding来充分捕获整个上下文`。

在我们的模型中，候选边之间的权重也根据句子的位置进行调整。从表3中可以看出，基于句子位置的边权值调整对SemEval2010和Nguyen2007的影响较大。如果不使用它，性能可能会下降2%。

## 3、超参数分析

图4显示了$k$(根据句子位置调整边缘权重的参数)、$p_s$(根据权重分布去除句子和候选词之间边的参数)和$d f_θ$(根据文档频率排除候选词的参数)的超参数整定。注意，参数$k$的调优研究只适用于长文档。对于少于10句话的短文档，$k$值设为10。参数$p_s$只适用于较短的文档，因为由于计算成本的原因，对于较长的文档，句子节点不会被添加到增强图中。

![1670853380489](D:%5CTypora%5Cuser-image%5C1670853380489.png)

结果表明，尽管k需要针对不同的数据集进行调整，但通过句子位置调整候选词的边权重可以提高模型的性能。添加句子节点可以略微提高短文档集的性能，但句子节点可能与所有候选词节点都没有很强的关系。$d f_θ$对短文档集- Inspec和SemEval2017的影响较小。在长文档集(SemEval2010和Nguyen2007)上调优$d f_θ$后，F1@15的性能可以提高约2%。

## 4、案例研究

AGRank与AttentionRank在短文档上的表现密切相关。为了观察AGRank和AttentionRank之间的差异，我们在SemEval2017中随机选择一个文档。图5的热图展示了两种模型计算出的候选对象的重要性得分。我们将原始分数标准化，用热图突出候选词。标记的关键字是粗体、斜体和下划线。AGRank的关键词“construct model”和“low emotional involvement”得分更高，而AttentionRank的“在线教学改革”得分更高。由于AttentionRank使用的是累积的自我注意力，所以长且有多个单词的候选词得分更高。

![1670903998616](D:%5CTypora%5Cuser-image%5C1670903998616.png)

JointModeling在长文档集SemEval2010上表现良好。图6显示了JointModeling和AGRank在SemEval2010文章中所选段落上的性能。热图显示了两种模型在策略上的差异。AGRank的候选对象比JointModeling少，这归因于我们的图修剪步骤。去除高文档频率和小邻居边权值的候选对象。由于增强图的边权重是基于预训练BERT模型提取的注意力生成的，AGRank给“commitment”和“Bayesian games”打了高分。

# 五、相关工作

![1670911507003](D:%5CTypora%5Cuser-image%5C1670911507003.png)

# 六、局限性、结论和未来的工作

**局限性：**图增强过程设计了大量的超参数，并且需要针对不同领域的数据集进行调优，以获得最佳性能。目前无法进行自动化超参数调优。

**结论：**基于句子位置的边权重调整对长文档集有更高的影响；添加文档和句子节点可以提高短文档集的性能。