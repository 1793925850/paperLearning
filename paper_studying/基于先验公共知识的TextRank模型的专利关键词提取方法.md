# 摘要

对于大量的专利文本，如何以无监督的方式提取关键词是一个非常重要的问题。现有的方法只对专利文本本身的信息进行分析。本文提出了一种有效利用先验公共知识的改进TextRank模型。

> 具体而言，首先考虑以下两点：

(1)针对每个专利文本构建TextRank网络；

(2)基于公共字典数据构建先验知识网络，其中网络边代表字典条目中所有词典词之间的先验解释关系。

然后，设计了改进的专利文本TextRank网络节点评分值评估公式，其中引入了先验知识网络中的先验解释信息。

最后，通过查找节点评分值较高的top-k节点词提取专利关键词。

在实验中，使用专利文本聚类任务来检验所提方法的性能，并进行了多个对比实验。

# 一、介绍

一般来说，专利内容可以用一些关键词来很好地表示，这些关键词也称为专利关键词。这些关键词可以广泛应用于文本挖掘中，如自动摘要生成、专利新颖性发现、文本聚类和分类。

专利文本作为一种半结构化文本，其段落和句子结构相对规整。因此，TextRank[7]作为一个基于图的分析模型被有效地用于提取专利关键词。对于现有的TextRank方法，它们使用PageRank公式基于所有可能单词之间的共现关系计算节点秩值。然而，`这些方法并没有考虑术语节点重要性与公共常识的原始差异`(也就是一些专业术语并不与人们常用语言相似)。因此，本文通过引入先验知识网络，提出了一种改进的TextRank模型，本文称之为PrTextRank。

在PrTextRank中，首先将专利文本建模为经典的TextRank网络，将公共字典数据建模为先验知识网络。在先验知识网络中，节点权重也通过PageRank公式计算，边缘权重通过字典条目中节点词的共现度计算。然后，将先验知识网络中的先验信息整合到专利TextRank网络中，设计了一种新的节点秩值评价方法。最后，像标准TextRank模型一样，通过查找节点秩值较高的top-k节点词提取专利关键词。

本研究的主要贡献如下：

1. 提出了一种具有先验公共知识的改进TextRank模型，有效地用于专利文本关键词提取。
2. 针对专利文本聚类任务，采用了几种聚类方法进行了实验，其中考虑了几种比较方法，包括我们提出的TF-IDF、TextRank和TopicalPageRank。实验结果表明，该方法具有良好的性能。
3. 本文还对新闻文本和食品流行文本等其他类型的文本进行了扩展实验分析。相应的实验结果也表明了该方法的有效性。

# 二、相关工作

## 1、关键词提取

关键词提取被分为有监督策略和无监督策略。

有监督关键词提取方法可以看作是一种二进制分类处理，需要标记的语料库数据来训练分类函数以获得良好的性能。然而，有监督关键词提取方法过于依赖标记语料库。由于手工贴标签费时费力，监督方法在许多应用场景中会受到限制。

目前，越来越多的研究人员关注无监督关键词提取问题。这类方法通常设计不同的评分标准对候选关键词进行排名，提取排名前k的单词作为关键词。一般来说，无监督提取方法可分为三大类:统计方法、词图方法和潜在狄利克雷分配(LDA)方法。

最经典的统计方法是TF-IDF，其适用性较强，但主要依赖词频信息，会忽略文本的语义特征。另一种著名的无监督方法是词图方法。受到PageRank算法的巨大成功及其广泛应用的启发。

## 2、基于文本挖掘的专利分析

随着专利文本的标准化和专业化，文本挖掘在专利分析中得到了广泛的应用。在将文本挖掘方法应用于专利分析领域时，大多数人关注的是有意义关键词的提取。技术演化分析、新技术发现和专利检索都是专利分析的重要任务。

## 3、聚类算法

目前常用的聚类方法有划分方法、分层方法、基于密度的方法、图聚类方法等。

基于划分的聚类算法迭代地将数据划分到不同的聚类中，直到同一聚类中的点之间的距离足够近，而不同聚类中的点之间的距离足够远。其中，最经典的基于划分的聚类算法是k-means。K-means算法简单高效，但需要预先设定聚类数量，对初始聚类中心的选择敏感。

分层聚类算法将最近的点组合成一个聚类，然后将最近的聚类组合成一个大聚类，直到所有点组成一个聚类。这些方法虽然不需要预先设置簇数，但计算复杂度非常高。

基于密度的聚类算法通过密度估计实现不规则形状聚类，并根据区域内的点密度是否超过阈值来决定是否继续聚类。一种经典的算法是基于密度的带噪声应用空间聚类(DBSCAN)。该算法虽然可以实现不规则形状的聚类，但其性能对条件参数的依赖性较大。

图聚类算法基于图论，将数据视为图空间中具有连通边的点，通过切割图来实现聚类。一个经典的算法是谱聚类。谱聚类算法依赖于相似矩阵的输入，实现简单，但对初始参数的选择也很敏感。

# 三、提出的方法

## 1、概述

考虑先验知识网络的引入，本文设计了新的模型框架，如图1所示。

![1669886861232](D:%5CTypora%5Cuser-image%5C1669886861232.png)

本研究首先对专利文本进行预处理，获得候选关键词;其中，候选关键词识别的准确性将直接影响最终提取的关键词质量。同时，对公共字典数据也进行了预处理。然后，将每个专利文本建模为TextRank网络，并基于公共字典数据构建先验知识网络。结合先验知识网络中的先验信息，设计了改进的节点秩值评价公式。最后提取节点值较高的top-k节点作为专利关键词。

## 2、TextRank模型

![1669887190848](D:%5CTypora%5Cuser-image%5C1669887190848.png)

## 3、先验知识网络

通常，公共词典中的词条都是由领域专家精心构建的。它们应该涵盖广泛的领域，具有权威性。基于以上考虑，可以基于公共字典数据构建有向先验知识网络，其中网络节点代表字典词，网络边代表字典词之间的解释关系。

![1669957206756](D:%5CTypora%5Cuser-image%5C1669957206756.png)

部分先验知识网络如图3所示。网络中的节点大小根据它们的入度值设置。我们认为，一个节点被解读的次数越多，它就越有可能是一个专业词条，它所代表的意义也就越具体。从图中可以看出，“电子计算机”这个词的in-degree值非常高，反映出这个词被解释的次数更多，内容也更具体。

在构造网络边时，我们记录两个字典词之间边的共现次数。在计算先验知识网络中的边缘权重(以上共现时间值)后，利用PageRank迭代方程进一步计算节点权重(节点i的$nw_{PKN}(i)$)。

## 4、优先关键词的重要性

在传统的TextRank模型中，所有候选关键字都被赋予相同的初始重要值。但在本研究中，作者认为在公共字典下专利文本可以考虑一些关键字的先验信息。

首先，介绍了经典的TF-IDF计算方法。词频(TF)是指某个词在给定文本文档中出现的频率。公式如下：
$$
TF_{ij}
=\frac{n_{ij}}{\sum_kn_{kj}}
$$
其中，$n_{ij}$表示文档$d_j$中单词$t_i$的出现次数，分母表示文档$d_j$中所有单词的出现次数的总和。

逆文档频率(IDF)表示语料库中包含某个单词的文档的出现频率。如果少数文档中包含某个关键字i，则说明关键字i具有较好的辨别能力，其IDF值较高。公式如下：
$$
IDF_{i}
=log\frac{|D|}{|\{j:t_i\in d_i\}|+1}
$$
其中，$|D|$表示语料库中的文档数量。分母表示包含关键字$t_i$的文档数量，加1是为了防止无意义的0值。

为TextRank网络中的每个节点词引入一个节点流行度。具体定义如下：
$$
pd_{i}
=\displaystyle\sum_{n\in as(i)}nw_{PKN}(i,n)
$$
其中，$nw_{PKN}(i,n)$表示在先验知识网络中，与专利节点词$v_i$相关的n个节点的权重。综合以上思路可知，$pd_i$越大，专利节点词$v_i$解释其他词的次数越多，因此专利节点词$v_i$的重要性越低。那么，文档$d_j$中专利节点词$v_i$的优先级可以表示为：
$$
pi(v_i,D_j)
=\frac{tf_{ij}\cdot idf_{i}}{\sqrt{pd_i+1}}
$$
所以，我们可能会认为，如果任何候选词可能是一个有效的关键字，那么它的优先重要性应该更高。

## 5、转移因子计算

在TextRank模型中，为了计算节点的秩值，需要根据实际问题的要求计算边缘权值，也称为边缘上的转移因子值。

一方面，我们认为一条边上的传递因子值与该边连接的两个节点词n和n’的共现频率$f_{n'}$有关；另一方面，我们可以利用先验知识网络中的一些先验信息来计算转移因子的值。本研究采用联想记忆策略。联想记忆是对新信息和已知事物的联想，是人脑的核心功能。可以认为，人脑的学习过程可能是神经元产生、删除和联想的过程，也是联想记忆的过程。因此，如果将先验知识网络中的每一个实体看作是一个神经元，两个实体之间的连接被认为是关联关系，我们可以通过计算它们的连接强度来计算两个实体之间的关联关系。具体公式如下：

![1669962844390](D:%5CTypora%5Cuser-image%5C1669962844390.png)

其中，$\lang n^{ijk},n'^{ijk}\rang$表示先验知识网络中两个节点$n$和$n’$之间的连接，$Co$表示字典条目中两个节点词的共现次数。$l_n$和$l_{n'}$分别表示该句中的相对位置索引值。M表示连接两个节点$n$和$n’$的最大联想跳数，$N$为先验知识网络中所有节点的总数。这里设置M=2为默认值，以降低计算复杂度。

另外，在上述式中，如果M步内没有有效的关联访问，则认为两个节点词之间没有有效关联，则设置$U^p_{n'}$为$\frac{1}{10}$。这意味着，如果它们对两个节点词有先验联想记忆信息，并且在给定的专利文本中，两个节点词出现在同一个滑动窗口中，那么它们的转移因子值应该更高。

最后，我们可以在改进的TextRank模型中引入以下传递因子计算公式：
$$
W^p_{n'}=f_{n'}\cdot U^p_{n'}
$$

## 6、 新关键词秩值的计算与提取 

根据以上描述，我们可以直接引入以下改进的节点秩值计算公式：

![1669963925330](D:%5CTypora%5Cuser-image%5C1669963925330.png)

其中，d为与原始TextRank模型相同的阻尼系数，$pi(v_i,D_i)$为计算的优先重要性，$W^p_{ij}$为转移因子值。

根据以上讨论，PrTextRank的方法过程可以总结如下：

![1669964070476](D:%5CTypora%5Cuser-image%5C1669964070476.png)

# 四、实验与分析

首先介绍了实验数据集和性能评价指标。然后，报告三种聚类方法下四种关键词提取方法的性能结果。最后，将在另一个数据集上进一步测试PrTextRank的可用性。

## 1、数据集

实验专利文本语料库由常州百腾科技有限公司提供。根据IPC分类标准，使用了电气类下的三种专利文本数据库，每个数据库中有1000个专利文本，总共使用3000个专利文本作为数据集一。

专利文本作为半结构化文本的典型代表，不仅包含了申请日期、IPC分类号等结构化信息，还包含了说明技术重点的标题、概括技术内容的摘要、揭示详细技术范围的权利要求书等非结构化信息。在本研究中，使用了专利文本的标题、摘要和权利要求书。

此外，本研究使用其它论文中使用的数据集，其中包含了953篇搜狐体育新闻文本。同时，从Foodbk中捕获953个文本作为另一个文本集。因此，以上两类文本的1906个文本作为数据集二。

先验知识网络的构建基于《汉语词典》，词典中包含了涉及各个领域的条目及其解释性信息。在构建先验知识网络时，首先对口译词进行分词和去停词预处理，然后利用词条与口译词之间的关系构建网络。

## 2、实验方法

### 2.1、算法设置

为了检验该方法的性能，我们使用提取的关键字来表示专利文本并进行聚类分析。如果提取的关键词能很好地代表专利文本，则会得到高质量的聚类结果。采用K-means、DBSCAN和经典谱聚类三种聚类方法进行性能分析。

在我们的实验中，滑动窗口大小设置为7，计算rank值的迭代时间设置为50，阻尼系数默认设置为0.85,TopicalPageRank主题数量为5。因为数据集I的类别数是3，所以K-means的类别数设为3。谱聚类采用k近邻表示相似矩阵，n_neighbors设为100，最终聚类个数为3。在DBSCAN集群中，ε为1,MinPts为4。

### 2.2、评价指标

对于性能评价，常用的三个评价指标是Precision (P)、Recall (R)和F1- score (F1，平衡F分数，它被定义为精准率和召回率的调和平均数)。相应的计算可以写成：

![1669964883658](D:%5CTypora%5Cuser-image%5C1669964883658.png)

其中，k为聚类个数，$TP_i$、$FN_i$、$FP_i$分别为第i类的真阳性、假阴性、假阳性个数。$TP_i+FP_i$表示预测为正的样本数，$TP_i+FN_i$表示实际为正的样本数。

## 3、结果与分析

这里分别比较了全文词和关键词的聚类性能。接下来，研究了PrTextRank在不同算法设置下的性能。然后，将PrRankText的性能与相关方法进行了比较。最后，报告了比较方法在非专利文档(数据集II)上的关键词提取性能结果。

### 3.1、关键词聚类的有效性分析

为了验证使用关键词进行文本聚类的有效性，我们以全文单词和PrTextRank关键词作为不同的实验条件，其中考虑了三种聚类算法。此外，文中提到的基线卷积神经网络(CNN)也可以作为比较方法。对于CNN来说，数据集I中的3000篇专利文本被分成训练数据和测试数据，分别占80%和20%。CNN方法从训练和测试数据中提取12100个特征作为CNN输入，每个特征处理为200维向量。在我们的实验中，滤波器数量设置为128个，滤波器窗口大小为3，卷积步长为1。在池化层选择最大轮询，保留最大的特征项。为了防止过拟合，设置dropout率为0.5。通过添加一个扁平层来压缩矢量维度。最后，通过两个全连接层，将三种类型的专利文本相关的向量长度缩小到3。结果如图4所示。

![1669966681060](D:%5CTypora%5Cuser-image%5C1669966681060.png)

如图4所示，使用关键词的聚类性能略低于使用全文词的聚类性能。然而，上述性能损失似乎非常小。此外，CNN分类得到的性能结果达到最大值84.5%，比采用谱聚类的PrTextRank关键词方法得到的最大值高2.7%。然而，CNN方法需要预先训练，是一种监督方法，而PrTextRank是一种无监督方法。

因此，我们可以认为，使用少数关键词作为整个专利文本的代表可以实现有效的文本聚类。

### 3.2、不同关键字数目的性能分析

这里，我们使用k-means聚类来比较不同关键字个数下的聚类性能。性能结果如图5所示。因为我们的实验专利文档只使用了标题、摘要和权利要求书，因此我们将提取关键字的数量范围设置为3到9。

![1669967004928](D:%5CTypora%5Cuser-image%5C1669967004928.png)

由图可知，当关键字个数为6时，PrTextRank的性能最好。当数字从1增加到6时，性能也会增加，而当数字进一步增大时，性能会下降。对于以上结果，我们可能会认为，更多的关键词将冗余用于表示专利文本，导致聚类性能下降。而由图5可知，TextRank和TF-IDF的最佳关键字数为7。此外，PrTextRank得到了比两种比较方法更高的性能结果。

### 3.3、不同算法设置对性能的影响

这里，表1、2、3展示了PrTextRank中不同特征设置在不同聚类方法下的驱动能力。其中，基本模型设为TextRank，TextRank + $P_i(V_i, D_j)$为先验重要性影响，TextRank + $W_{n '}$为改进转移因子影响。

![1669967351639](D:%5CTypora%5Cuser-image%5C1669967351639.png)

以上实验结果表明，两种新设计的算法策略是非常有效的。具体而言，在经典TextRank模型中加入节点的先验重要性后，精度值分别提高了6.16%、6.26%和5.79%。召回值分别提高1.8%、2.98%和6.48%。F1-Score分别提高3.88%、4.68%和4.48%。根据以上结果，我们可以认为，有效的专利文本关键词可能是指更专业而不是常见的词，我们之前的考虑应该在PrTextRank模型中合理引入。

进一步发现，新设计的转移因子的有效性应高于节点先验重要性的有效性。这些结果可能与TextRank的固有思想是一致的，即一个节点的重要性取决于相邻节点的贡献，而贡献主要取决于相邻节点之间的边权。

最后，当先验知识网络中的两个策略(先验节点重要性和改进的转移因子)结合使用时，可以进一步提高聚类性能。以上结果表明，PrTextRank中两个新的考虑因素是合理和有效的。

### 3.4、性能分析及相关方法

本文利用TF-IDF、经典TextRank和TopicalPageRank(简称TPR)对PrTextRank进行了进一步的性能分析。相应的结果如表4所示，取10次运行的平均结果。![1669968626809](D:%5CTypora%5Cuser-image%5C1669968626809.png)

在F1-Score性能指标上，TextRank方法比TF-IDF方法分别高出2.37%、4.64%和2.12%。而且，TopicalPageRank的性能明显优于TextRank。特别是在谱聚类方法下，TopicalPageRank得到的F1-Score分别比TF-IDF和TextRank高出17.22%和15.1%。

但在三种聚类算法下，PrTextRank的f1评分性能均比TopicalPageRank高，分别为5.88%、7.87%和3.6%。以上结果的原因可能是TopicalPageRank可以覆盖大部分的文本主题，而专利文本的主题较少，专业术语词较多，利用先验知识可以有效提高专业术语词的权重。

### 3.5、复杂度分析

与传统的TextRank相比，PrTextRank需要额外构造先验知识网络，这可能会增加计算复杂度。因此，在数据集i上进一步考察了PrTextRank和TextRank的运行复杂度。对于51字的文档，TextRank方法的运行时间和内存使用量分别为0.38 s和580.0 KB。PrTextRank方法对应的值为1.26 s和1008.0 KB。

另一个3000个文档，12100字的情况下，TextRank方法的运行时间和内存使用量分别为990.21 s和79376.0 KB，而PrTextRank方法对应的值为3113.59 s和188,280.0 KB。由以上结果可知，在构建和使用先验知识网络时，PrTextRank需要额外的运行时间和运行内存。但是，考虑到性能的明显提高，这些额外的计算开销应该是值得的。

### 3.6、扩展实验分析

为了进一步验证PrTextRank的性能，我们使用数据集II对一般文本关键词提取问题进行了研究。结果如图6所示。

![1669968948741](D:%5CTypora%5Cuser-image%5C1669968948741.png)

图6的结果表明，PrTextRank在数据集II中也取得了很好的性能。与TF-IDF和TextRank相比，PrTextRank的性能分别提高了4.92%、8.16%和10.98%。与TopicalPageRank方法相比，PrTextRank的性能也分别提高了0.44%、1.68%和2.78%。这些结果与在专利文本数据集上的实验结果一致。此外，由于数据集II包含体育新闻文本和美食流行文本，主题完全不重叠，TopicalPageRank提取的关键词可以有效区分不同的文本。尽管如此，我们提出的方法也获得了比TopicalPageRank更好的性能结果，体现了引入先验公共知识网络的良好效果。

### 3.7、具有潜在语义指标的扩展分析

基于关键字的文档检索是最简单、最常用的方法。然而，对于许多结构和内容复杂的文档来说，仅仅依靠关键词匹配来满足文档索引的要求似乎是不够的。因此，我们还应注意文档中的潜在语义信息。

Dumais等提出的潜在语义索引(LSI)是通过查找文档词之间的潜在相关性来实现文档索引的强大工具。在更具体的应用中，根据PrTextRank提取的关键字，LSI可用于复杂的文档索引任务。

# 五、结论

在本研究中，我们在传统的TextRank模型中引入先验公共知识，提出了一种新的无监督关键词提取方法。其中，引入先验信息的两个方面，即先验节点重要性和改进的传递因子计算策略。实验结果表明，该方法在专利文本关键词提取问题上比传统方法取得了更好的性能。此外，该方法不需要额外的参数设置，可广泛应用于不同的应用场合。