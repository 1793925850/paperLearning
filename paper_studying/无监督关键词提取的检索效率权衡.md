# 摘要

在本文中，我们探索了一种新的无监督方法，在构建令牌图之前，以顺序的形式合并文档的部分。此外，通过利用个性化的PageRank，在节点排名期间考虑这些子短语的频率和令牌长度，我们展示了最先进的检索能力，同时比当前最先进的无监督检测器(如YAKE和MultiPartiteRank)快两个数量级。通过在不到一分钟的时间内计算由1400万份文档组成的生物医学语料库的关键字，证明了该方法的可扩展性。

# 一、介绍

令牌在词法分析中是标记的意思。

无监督方法可以进一步分为基于令牌共出现构造图的方法和利用n-grams统计特性的方法。

本文贡献：

1. 我们提出了`RaKUn 2.0`，一个基于图的关键字提取器，在考虑检索能力和性能时优化了检索效率优化；
2. 基于多边形的可视化，适用于研究和比较多个关键字检测算法的多个标准；
3. RaKUn 2.0针对强基线(包括最近引入的KeyBERT)的广泛基准测试；
4. 基于Friedman-Nemenyi的算法平均排名分析(及其相似性)。

# 二、相关工作

第一个分支的方法是基于文本到图形的转换(也就是基于图的方法)，然后对得到的图进行后续处理。这种方法能够利用文档的多层结构，分层结构。图2显示了一个令牌图示例。

![1675565671189](D:%5CTypora%5Cuser-image%5C1675565671189.png)

本文的目的之一是对所讨论的算法进行综合评估，包括`计算时间`和`复制率`(在检测到的关键字空间中一个标记的频率)。

# 三、提出的算法

该方法的核心思想来源于最近的一篇基于元顶点的关键短语检测论文RaKUn。我们将提议的方法称为RaKUn 2.0。一个高层次的概述显示为算法1。

![1675646502997](D:%5CTypora%5Cuser-image%5C1675646502997.png)

主要的步骤包括：

1. 令牌化(标记)；
2. 令牌合并(标记合并)；
3. 文档图构建；
4. 节点评级。

RaKUn 2.0不先构造(更大的)服从于节点合并到元顶点的图，而是在序列级别进行合并步骤，使其更高效。基于这样一种观察，即预先合并接近的令牌已经提供了足够的结果——通过只考虑彼此接近的令牌，不需要专门的字符串比较度量(可能很昂贵)，这大大加快了检测过程。第二个大大加快了进程的想法与双格哈希有关。它指的是在每个双(成对的)图及其在文档中的计数之间构建映射，支持如下所示的快速查找此信息。对于每个后续令牌对$(t_i, t_j)$检索术语计数(它们在令牌化过程中预先计算)。我们接下来计算合并阈值分数为：

![1675648167305](D:%5CTypora%5Cuser-image%5C1675648167305.png)

其中$t_i$和$t_j$是两个后续令牌，$b_{ij}$是由这两个令牌组成的bi-gram。如果MScore低于用户指定的阈值(超参数)，`合并的令牌将作为一个新的令牌添加到令牌空间中`，并且两个单独令牌的术语计数将由MScore减少为$\# t_i = MScore * \# t_i$，即与计算出的分数相乘。MScore的值小于1，表示多词关键字较多(单个词没有被强调)；V值大于1，表示单个令牌关键字较多。因此，MScore作为一个中间步骤，在排名步骤中强调特定的令牌。

令牌图G是根据修改后的令牌列表构造的，它将后续的小写令牌视为边。每当给定的bi-gram重复时，边权值都会增加-强调共现标记之间的转换。下一步是节点排名。在这里，为每个(预合并的)令牌分配一个实值分数。这一步将为每个令牌生成实值分数(在0到1之间)。最后一组分数是通过计算PageRank分数和令牌长度之间的元素乘积来获得的。这一步强调较长的关键字。我们遍历有分数的标记空间，并删除大小写级重复项(例如，' City '和' City ')。

所描述的关键字检测算法的构思简单。这一特性也与它的计算复杂性产生了共鸣。让$T$表示合并步骤之后的令牌数量(对于运行时，基数差异可以忽略不计)。图构造和合并都需要一次遍历令牌序列$(O(|T |)$。计算上最昂贵的部分是个性化PageRank的计算。理论上，PageRank的复杂度为$O(|T | + l)$，其中$l$为构建的令牌图中的链接数。在实践中，得到的图是非常稀疏的-只有选定的双图同时出现。在相反的情况下，密集的、团状的图形将产生，这意味着在高度多样化的上下文中出现令牌，这是极不可能的。最后一步需要根据分数对令牌进行排序。这产生了$O(|T | log |T |·l)$的最终复杂度。假设图非常稀疏(正如在实验中观察到的那样)，复杂度与合并步骤后令牌集中的令牌数量保持线性关系。

# 四、评估

精度、召回率、F1；

复制率、时间性能(归一化逆时间)；

![1675819728642](D:%5CTypora%5Cuser-image%5C1675819728642.png)

# 五、结果

算法运行时间的摘要(相对于其他算法)显示在图3中。

![1675819904915](D:%5CTypora%5Cuser-image%5C1675819904915.png)

## 1、扩展到14M的文档

![1675820545767](D:%5CTypora%5Cuser-image%5C1675820545767.png)

# 六、讨论和结论

本文提出了一种无监督关键词检测方法，旨在提高计算时间和检索性能的极限。本文的主要贡献是一种关键短语检测算法，它比当前最先进的方法执行得要快得多，同时保持检索性能。新颖的算法引入了将令牌序列转换为图的方法，并通过在序列级别构造元顶点来重新解决元顶点的问题，这大大加快了速度。另外，通过利用个性化的PageRank，全局令牌信息与令牌长度一起被纳入关键字排名。通过对已建立的基线进行广泛的基准测试，本文提出了一个包含检索功能的评估，但进一步详细说明了检索关键字之间的计算时间和重复率。

